{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb19626f-5c64-431b-bdff-b914924c37b6",
   "metadata": {},
   "source": [
    "# PCA and RF Classifier Analysis of Paired Datasets\n",
    "### UPDATED May 13, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e2ce1c-9ef3-4ec6-b48b-ceddc14e2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dependencies and import packages:\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "import mpl_axes_aligner\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1140b6d-3cb7-4deb-834f-0f1fd39a30bc",
   "metadata": {},
   "source": [
    "**Load in data and preprocess for analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7306dfd6-fe3e-4958-a7be-82b6d87cadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all combinations of disorders:\n",
    "pairwise = [['ASD', 'AD'], ['ASD', 'PD'], ['ASD', 'MS'],\n",
    "            ['AD', 'PD'], ['AD', 'MS'],\n",
    "            ['PD', 'MS']]\n",
    "\n",
    "# colors kept for all analyses:\n",
    "color_map = {'AD': '#666666',\n",
    "             'ASD':'#F0027F',\n",
    "             'MS': '#FDC086',\n",
    "             'PD': '#7FC97F'}\n",
    "\n",
    "# load in data:\n",
    "df = pd.read_csv('../Data/20440_cleaned_data.csv')\n",
    "\n",
    "diagnosis = ['AD', 'ASD', 'MS', 'PD']\n",
    "# remove all genera with 0s in an entire disorder:\n",
    "for diag in diagnosis:\n",
    "    for feature in df.columns:\n",
    "        drop = 0\n",
    "        for val in df[feature].loc[df['Diagnosis'] == diag]:\n",
    "            if val != 0:\n",
    "                drop +=1\n",
    "        if drop == 0:\n",
    "            df = df.drop([feature], axis=1)\n",
    "\n",
    "\n",
    "# add diagnosis column\n",
    "df_pair = []\n",
    "for pair in pairwise:\n",
    "    df_i = df.loc[(df['Diagnosis'] == pair[0]) | (df['Diagnosis'] == pair[1])]\n",
    "    df_pair.append(df_i)\n",
    "\n",
    "\n",
    "# For dropping diagnosis column so we can feed data in:\n",
    "data_pair = []\n",
    "\n",
    "# drop diagnosis column for analysis:\n",
    "for dataset in df_pair:\n",
    "    data_pair_i = dataset.drop(['Diagnosis'], axis=1) # data without diagnosis column\n",
    "    data_pair_i = data_pair_i.drop(['Unknown'], axis=1)\n",
    "    data_pair_i = data_pair_i.loc[:, (data_pair_i != 0).any(axis=0)] # delete any columns with all zeros\n",
    "    data_pair.append(data_pair_i)\n",
    "\n",
    "# make a list of diagnoses:\n",
    "diagnosis_pair = []\n",
    "\n",
    "for dataset in df_pair:\n",
    "    diagnosis_pair.append(list(dataset[\"Diagnosis\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b3868-ec59-47d9-b0eb-172248ae7fbf",
   "metadata": {},
   "source": [
    "**Standardize within genera:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84daa25-127e-4c80-800a-3997af9bb32d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data_pair:\n\u001b[1;32m      3\u001b[0m     columns \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m----> 4\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mStandardScaler()\u001b[38;5;241m.\u001b[39mfit(i)\n\u001b[1;32m      5\u001b[0m     data_pair_1\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mtransform(i), columns\u001b[38;5;241m=\u001b[39mcolumns))\n\u001b[1;32m      7\u001b[0m data_pair \u001b[38;5;241m=\u001b[39m data_pair_1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "data_pair_1 = []\n",
    "for i in data_pair:\n",
    "    columns = i.columns\n",
    "    scaler = preprocessing.StandardScaler().fit(i)\n",
    "    data_pair_1.append(pd.DataFrame(scaler.transform(i), columns=columns))\n",
    "\n",
    "data_pair = data_pair_1 # just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05768029-6861-43b9-a5da-8197379ee053",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba6c48-3c97-4399-9157-24f8f290f1c4",
   "metadata": {},
   "source": [
    "**Now we perform PCA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01a795-46c7-4cf9-989a-f015286e9a34",
   "metadata": {},
   "source": [
    "**Run PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c8257-9c5c-472f-bc27-28242d7bd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for storing anything we need for easy access:\n",
    "out_df_pair = [] # results of PCA\n",
    "var_ratio_pair = [] # varaince captured by each PC\n",
    "pcs_pair = [] # the loadings\n",
    "loadings_pair = [] # dataframes of the loadings\n",
    "\n",
    "for data in data_pair_1:\n",
    "    # run PCA, capture 90% of variance:\n",
    "    pca = PCA(n_components=.90)\n",
    "    out = pca.fit_transform(data)\n",
    "\n",
    "    columns_list = []\n",
    "    for i in range(len(out[0])):\n",
    "        columns_list.append(\"PC\" + str(i + 1))\n",
    "\n",
    "    # add all information to lists for later access in a corresponding form:\n",
    "    out_df = pd.DataFrame(out, columns=columns_list)\n",
    "    out_df_pair.append(out_df)\n",
    "    var_ratio_pair.append(pca.explained_variance_ratio_)\n",
    "    pcs_pair.append(pca.components_)\n",
    "    loadings_pair.append(pd.DataFrame(pca.components_, columns=data.columns, index=out_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47b143-db93-4a68-af18-7aa2c998c8ef",
   "metadata": {},
   "source": [
    "**Visualize variance ratio explained by each component:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406fd8c-27fd-45de-b9f5-bde91b1d918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 200)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "for i in range(len(out_df_pair)):\n",
    "    pc = np.linspace(1, len(out_df_pair[i].columns)+1, len(out_df_pair[i].columns))\n",
    "    axes[i].scatter(pc, var_ratio_pair[i])\n",
    "    axes[i].set_title('Explained variance ratio by component: ' +  str(pairwise[i]))\n",
    "    axes[i].set(xlabel='Component')\n",
    "    axes[i].set(ylabel='Explained variance ratio');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a867c-2829-4165-b495-98ba44cc8610",
   "metadata": {},
   "source": [
    "**Visualize clustering by diagnosis with first two PCs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af42f3-5419-498a-9f0f-58efc826a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 200)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "for i in range(len(out_df_pair)):\n",
    "    \n",
    "    diag_1 = []\n",
    "    diag_2 = []\n",
    "    \n",
    "    for j in range(len(diagnosis_pair[i])):\n",
    "        if diagnosis_pair[i][j]==pairwise[i][0]:\n",
    "            diag_1.append(j)\n",
    "        if diagnosis_pair[i][j]==pairwise[i][1]:\n",
    "            diag_2.append(j)\n",
    "    \n",
    "    # plot PC1 v PC2, indicating which indices of these are which disease:\n",
    "    axes[i].scatter(out_df_pair[i]['PC1'][diag_1], out_df_pair[i]['PC2'][diag_1], label=pairwise[i][0], color = color_map[pairwise[i][0]], edgecolor='white')\n",
    "    axes[i].scatter(out_df_pair[i]['PC1'][diag_2], out_df_pair[i]['PC2'][diag_2], label=pairwise[i][1], color = color_map[pairwise[i][1]], edgecolor='white')\n",
    "    \n",
    "    \n",
    "    axes[i].legend();\n",
    "    axes[i].set(xlabel=\"PC1\")\n",
    "    axes[i].set(ylabel=\"PC2\")\n",
    "    axes[i].text(0.5, .15, \"variance explained by PC1 and PC2: \\n {:.4f}\".format(var_ratio_pair[i][0] + var_ratio_pair[i][1]), transform=axes[i].transAxes, horizontalalignment='center',\n",
    "    verticalalignment='top', bbox=dict(facecolor='gray', alpha=0.2))\n",
    "    axes[i].set_title(\"Classification of \" + str(pairwise[i]) + \" on PC1 v PC2\");\n",
    "    \n",
    "plt.savefig('../Figures/PCA_plots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffeb794-7716-4941-b393-f111458efa75",
   "metadata": {},
   "source": [
    "**Plot the loadings for the first principal component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5a2b4-7775-4df1-8af2-528500aaec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "load_list = []\n",
    "\n",
    "for i in range(len(pcs_pair)):\n",
    "    pcs = pcs_pair[i]\n",
    "    # create a dataframe with the load of the features in PC1:\n",
    "    load = pd.DataFrame(np.transpose(pcs), columns=['PC'+str(i+1) for i in range(len(out_df_pair[i].columns))])\n",
    "    load[\"feature\"] = list(data_pair_1[i].columns)\n",
    "    \n",
    "    # descending values\n",
    "    load1 = load.sort_values('PC1', ascending=False)\n",
    "    load1_feat = pd.DataFrame(load1[[\"feature\", 'PC1']], columns=['feature', 'PC1']) # for reference\n",
    "    load_list.append(list(load1_feat[\"feature\"]))\n",
    "    \n",
    "\n",
    "    load_out = pd.concat([load1_feat[:5], load1_feat[-5:]], ignore_index=True)\n",
    "    \n",
    "    # plot\n",
    "    sns.barplot(load_out, x='feature', y='PC1', ax=axes[i]);\n",
    "    axes[i].set_xticklabels(load_out['feature'], rotation=75);\n",
    "    axes[i].set_title(\"Loadings for PC1 for \" + str(pairwise[i]));\n",
    "\n",
    "plt.savefig('../Figures/PCA_load_plots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9d266-68a4-4425-9a72-b432b6b35c07",
   "metadata": {},
   "source": [
    "## Biplot creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66888211-0e26-48c3-a101-4698ddf8bcf5",
   "metadata": {},
   "source": [
    "**Define the function for biplot creation first:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6da6ed-bff6-4b10-b957-31558c001b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(dfScores, dfLoadings, ax):\n",
    "    ''' directly sourced from https://insidelearningmachines.com/biplot/ . \n",
    "    Altered to only show first four loadings (that contribute most to variance), \n",
    "    most negative and most positive from PC1 and PC2'''\n",
    "    \n",
    "    #make a scores plot\n",
    "\n",
    "    #set x-axis label\n",
    "    ax.set_xlabel(\"PC1\",fontsize=10)\n",
    "    #set y-axis label\n",
    "    ax.set_ylabel(\"PC2\",fontsize=10)\n",
    "    \n",
    "    #create a second set of axes\n",
    "    ax2 = ax.twinx().twiny()\n",
    "    \n",
    "    #setup font dictionary\n",
    "    font = {'color':  'black',\n",
    "            'weight': 'bold',\n",
    "            'size': 12,\n",
    "            }\n",
    "    \n",
    "    # sort the loadings plot:\n",
    "    dfLoadings = dfLoadings.sort_values('PC1', axis=1, ascending=False)\n",
    "    dfLoadings1 = dfLoadings.sort_values('PC2', axis=1, ascending=False)\n",
    "\n",
    "    # color in lines by PC and orient the labels\n",
    "    b = 0\n",
    "    v_orient = [\"top\", \"top\", \"top\", \"bottom\"]\n",
    "    h_orient = [\"left\", \"right\", \"right\", \"right\"]\n",
    "    col_pc = [\"red\", \"red\", \"blue\", \"blue\"]\n",
    "\n",
    "    list_show = [dfLoadings.columns.values[0], dfLoadings.columns.values[-1], dfLoadings1.columns.values[0], dfLoadings1.columns.values[-1]]\n",
    "    \n",
    "    #make a loadings plot\n",
    "    \n",
    "    for col in list_show:    \n",
    "        #where do our loading vectors end?\n",
    "        tipx = dfLoadings.loc['PC1',col]\n",
    "        tipy = dfLoadings.loc['PC2',col]\n",
    "        #draw the vector, and write label text for col\n",
    "        ax2.arrow(0, 0, tipx, tipy, color = col_pc[b], alpha = 0.5)\n",
    "        ax2.text(tipx*1.05, tipy*1.05, col, fontdict = font, ha = h_orient[b], va = v_orient[b])\n",
    "        b +=1\n",
    "\n",
    "    ax2.set_xlim(-.75, .75)\n",
    "    ax2.set_ylim(-.75, .75)\n",
    "    #align x = 0 of ax and ax2 with the center of figure\n",
    "    mpl_axes_aligner.align.xaxes(ax, 0, ax2, 0, 0.5)\n",
    "    #align y = 0 of ax and ax2 with the center of figure\n",
    "    mpl_axes_aligner.align.yaxes(ax, 0, ax2, 0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815386e3-d9ca-40b1-9626-784f8ce56c71",
   "metadata": {},
   "source": [
    "**Show the biplots:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640ebf0-02b9-4fe8-ac85-e83aaaab8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "plt.subplots_adjust(hspace=.2)\n",
    "\n",
    "for i in range(len(out_df_pair)):\n",
    "    \n",
    "    diag_1 = []\n",
    "    diag_2 = []\n",
    "    \n",
    "    for j in range(len(diagnosis_pair[i])):\n",
    "        if diagnosis_pair[i][j]==pairwise[i][0]:\n",
    "            diag_1.append(j)\n",
    "        if diagnosis_pair[i][j]==pairwise[i][1]:\n",
    "            diag_2.append(j)\n",
    "    \n",
    "    # plot PC1 v PC2, indicating which indices of these are which disease:\n",
    "    axes[i].scatter(out_df_pair[i]['PC1'][diag_1], out_df_pair[i]['PC2'][diag_1], label=pairwise[i][0], color = color_map[pairwise[i][0]], edgecolor='white', s=50)\n",
    "    axes[i].scatter(out_df_pair[i]['PC1'][diag_2], out_df_pair[i]['PC2'][diag_2], label=pairwise[i][1], color = color_map[pairwise[i][1]], edgecolor='white', s=50)\n",
    "\n",
    "    # add in the biplot\n",
    "    biplot(out_df_pair[i], loadings_pair[i], axes[i])\n",
    "    axes[i].legend(fontsize=15);\n",
    "\n",
    "    # also display variance captured by first two PCs\n",
    "    axes[i].set_xlabel(xlabel=\"PC1 ({:.2f} %)\".format(var_ratio_pair[i][0] * 100), fontsize=15)\n",
    "    axes[i].set_ylabel(ylabel=\"PC2 ({:.2f} %)\".format(var_ratio_pair[i][1] * 100), fontsize=15)\n",
    "\n",
    "    axes[i].set_xlim(-10, 10)\n",
    "    axes[i].set_ylim(-10, 10)\n",
    "    axes[i].set_title(\"Classification of \" + pairwise[i][0] + ' vs ' + pairwise[i][1], fontsize=20);\n",
    "\n",
    "plt.savefig('../Figures/PCA_biplots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe449f3-0dc5-402d-9882-4e5f5c44fdd0",
   "metadata": {},
   "source": [
    "**Plot the diseases against the first to loadings from the first PC to visualize any separation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8eaf1-3572-4b3f-8213-dc455c74921f",
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.figure(dpi = 300)\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "plt.subplots_adjust(hspace=.2)\n",
    "\n",
    "for i in range(len(out_df_pair)):\n",
    "    \n",
    "    diag_1 = []\n",
    "    diag_2 = []\n",
    "\n",
    "    feat_1 = load_list[i][0]\n",
    "    feat_2 = load_list[i][1]\n",
    "    \n",
    "    for j in range(len(diagnosis_pair[i])):\n",
    "        if diagnosis_pair[i][j]==pairwise[i][0]:\n",
    "            diag_1.append(j)\n",
    "        if diagnosis_pair[i][j]==pairwise[i][1]:\n",
    "            diag_2.append(j)\n",
    "    \n",
    "    # plot loading 1 and 2 from PC1, indicating which indices of these are which disease:\n",
    "    axes[i].scatter(data_pair_1[i][feat_1][diag_1], data_pair_1[i][feat_2][diag_1], label=pairwise[i][0], color = color_map[pairwise[i][0]], edgecolor='white', s=50)\n",
    "    axes[i].scatter(data_pair_1[i][feat_1][diag_2], data_pair_1[i][feat_2][diag_2], label=pairwise[i][1], color = color_map[pairwise[i][1]], edgecolor='white', s=50)\n",
    "    \n",
    "    axes[i].legend(fontsize=15);\n",
    "    \n",
    "    axes[i].set_xlabel(feat_1, fontsize=15)\n",
    "    axes[i].set_ylabel(feat_2, fontsize=15)\n",
    "\n",
    "    axes[i].set_title(\"Classification of \" + pairwise[i][0] + ' vs ' + pairwise[i][1], fontsize=20);\n",
    "\n",
    "plt.savefig('../Figures/PCA_feat_plots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac6a4c-1aa4-411a-ae58-ce1964497cfb",
   "metadata": {},
   "source": [
    "## RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921711c-57de-413c-97aa-8fa5c0fff382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will hold all important information in an easy-to-use format:\n",
    "diag_test_pair = [] #testing data\n",
    "diag_train_pair = [] #training data\n",
    "out_pair = [] # output of RF classification\n",
    "diag_predict_pair = [] #prediction output on test set\n",
    "rf_pair = [] # the actual classifier\n",
    "importance_feat = [] # the importances based on permuation testing\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(data_pair_1)):\n",
    "    # set up classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100) # 100 trees in the forest.\n",
    "    # 100 trees means 100 sub-samples of data\n",
    "    \n",
    "    # make training and testing sets:\n",
    "    feat_train, feat_test, diag_train, diag_test = sk.model_selection.train_test_split(data_pair_1[i], diagnosis_pair[i], test_size=0.70)\n",
    "    # chose a test size of 70%\n",
    "    \n",
    "    # train:\n",
    "    out = rf.fit(feat_train, diag_train)\n",
    "    \n",
    "    # test:\n",
    "    diag_predict = rf.predict(feat_test)\n",
    "\n",
    "    # store info:\n",
    "    diag_test_pair.append(diag_test)\n",
    "    diag_train_pair.append(diag_train)\n",
    "    out_pair.append(out)\n",
    "    diag_predict_pair.append(diag_predict)\n",
    "    # permutation testing with 100 repeats:\n",
    "    perm_importance = permutation_importance(rf, feat_test, diag_test, n_repeats=100)\n",
    "    importance_feat.append(perm_importance)\n",
    "    rf_pair.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287a61-a945-41e4-bb4e-1aa9a1d1b866",
   "metadata": {},
   "source": [
    "**Accuracy of classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc0c9f-d0c6-42b9-a539-03c83d7f4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(diag_test_pair)):\n",
    "    acc = sk.metrics.accuracy_score(diag_test_pair[i], diag_predict_pair[i])\n",
    "    print(\"accuracy for \" + str(pairwise[i]) + \" {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd0ca5-f2ad-4e33-8107-987ef4c2daa0",
   "metadata": {},
   "source": [
    "**Plot of most important features for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12459a72-60b8-47ee-acd9-641c8cbe379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_table_pair = []\n",
    "df_imp = []\n",
    "\n",
    "# store info in tables\n",
    "for i in range(len(data_pair_1)):\n",
    "    # find importance of each feature:\n",
    "    feat = data_pair_1[i].columns\n",
    "    feat_importance = rf_pair[i].feature_importances_\n",
    "    \n",
    "    # make and print table of ranked features by importance:\n",
    "    imp_table = pd.DataFrame(feat, columns=['features'])\n",
    "    imp_table['importance'] = feat_importance\n",
    "    imp_table_sort = imp_table.sort_values('importance', ascending=False)\n",
    "    imp_table_sort = imp_table_sort.round(3)\n",
    "    feat_sort = list(imp_table_sort['features']) # use this for plotting and storing the features\n",
    "    imp_table_pair.append(feat_sort)\n",
    "    df_imp.append(imp_table_sort)\n",
    "    # save them for later use:\n",
    "    imp_table_sort.to_csv('../Data/feature_importance/' + \"feature_importance_\" + pairwise[i][0] + '_' + pairwise[i][1] + '.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255f365-fbe1-4f1a-98f7-155e652c758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_data = []\n",
    "\n",
    "# get the data from the permutation testing:\n",
    "for i in range(len(pairwise)):\n",
    "    sorted_id = importance_feat[i].importances_mean.argsort()\n",
    "    imp_data.append(pd.DataFrame(importance_feat[i].importances[sorted_id].transpose(), columns=data_pair_1[i].columns[sorted_id]))\n",
    "\n",
    "# plot using a box and whisker plot:\n",
    "plt.figure(dpi = 300)\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "\n",
    "for i in range(len(pairwise)):\n",
    "    imp_data[i].boxplot(list(imp_data[i].columns[-5:]), grid=False, ax=axes[i], meanline=True, fontsize=12, notch=True)\n",
    "    axes[i].set_xlabel(xlabel=\"Genera\", fontsize=15)\n",
    "    axes[i].set_ylabel(ylabel=\"Importance Score\", fontsize=15)\n",
    "    axes[i].set_title(\"Feature importance scores for \" + str(pairwise[i][0]) + ' vs ' + str(pairwise[i][1]), fontsize=20);\n",
    "\n",
    "plt.savefig('../Figures/RF_importance_plots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffe8e1-ccd2-4f17-aaa4-f1c9460f5047",
   "metadata": {},
   "source": [
    "**XY scatter of important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c1032-c341-4e1b-8fa6-40437ae23bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 15))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "for i in range(len(data_pair_1)):\n",
    "\n",
    "    diag_1 = []\n",
    "    diag_2 = []\n",
    "\n",
    "    feat1 = imp_data[i].columns[-1]\n",
    "    feat2 = imp_data[i].columns[-2]\n",
    "    \n",
    "    for j in range(len(data_pair_1[i])):\n",
    "        if diagnosis_pair[i][j]==pairwise[i][0]:\n",
    "            diag_1.append(j)\n",
    "        if diagnosis_pair[i][j]==pairwise[i][1]:\n",
    "            diag_2.append(j)\n",
    "    \n",
    "    # use the top two most important features from the table of ranked importances\n",
    "\n",
    "    axes[i].scatter(data_pair_1[i].reset_index()[feat1][diag_1], data_pair_1[i].reset_index()[feat2][diag_1], label=pairwise[i][0], color = color_map[pairwise[i][0]], edgecolor='white', s=75)\n",
    "    axes[i].scatter(data_pair_1[i].reset_index()[feat1][diag_2], data_pair_1[i].reset_index()[feat2][diag_2], label=pairwise[i][1], color = color_map[pairwise[i][1]], edgecolor='white', s=75)\n",
    "    \n",
    "    axes[i].legend(fontsize=15);\n",
    "    \n",
    "    axes[i].set_xlabel(feat1, fontsize=15);\n",
    "    axes[i].set_ylabel(feat2, fontsize=15);\n",
    "    \n",
    "    axes[i].set_title(\"Classification of \" + str(pairwise[i][0]) + ' vs ' + str(pairwise[i][1]), fontsize=20);\n",
    "plt.savefig('../Figures/RF_feature_plots_paired.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efced763-5c8a-414b-be3b-9a5d95646dc4",
   "metadata": {},
   "source": [
    "**Look at Gini importance and get decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b90f9-0ed8-4c34-ba2a-a62448970379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followed this tutorial for getting image: https://naysan.ca/2019/11/26/visualize-a-decision-tree-with-sklearn/\n",
    "# i just plotted one of the trees:\n",
    "graphs = []\n",
    "Images = []\n",
    "for i in range(len(out_pair)):\n",
    "    out_file = sk.tree.export_graphviz(out_pair[i][1], label='all', feature_names=imp_table_pair[i], class_names= pairwise[i])\n",
    "    \n",
    "    graphs.append(pydotplus.graph_from_dot_data(out_file))\n",
    "    Images.append(Image(graphs[i].create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fab76f-96a2-4ece-940e-9caf869d6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a79f2-7e34-464a-ad23-49a5752f7d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
